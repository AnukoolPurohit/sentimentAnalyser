{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anukoolpurohit/anaconda3/envs/Torch10cuda/lib/python3.7/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from sentimentanalyser.data.text import TextList, ItemList, DataBunch, SplitData\n",
    "from sentimentanalyser.utils.data import Path, listify, random_splitter, compose, parallel, pad_collate, parent_labeler, read_wiki, grandparent_splitter\n",
    "from sentimentanalyser.data.samplers import SortishSampler, SortSampler\n",
    "from sentimentanalyser.utils.preprocessing import *\n",
    "from sentimentanalyser.utils.files import pickle_dump, pickle_load\n",
    "from sentimentanalyser.preprocessing.processor import TokenizerProcessor, NuemericalizeProcessor, CategoryProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_imdb = Path(\"/home/anukoolpurohit/Documents/AnukoolPurohit/Datasets/imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_tok = TokenizerProcessor()\n",
    "proc_num = NuemericalizeProcessor()\n",
    "proc_cat = CategoryProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0166337759f3425cae09a7e06847fa4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b60bbcd40247b890305de02e75f5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8e5428d2ee418185ec895a0c18542e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "il_imdb = TextList.from_files(path_imdb, folders=['train', 'test'])\n",
    "sd_imdb = il_imdb.split_by_func(partial(grandparent_splitter, valid_name='test'))\n",
    "ll_imdb = sd_imdb.label_by_func(parent_labeler, proc_x = [proc_tok, proc_num], proc_y=proc_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dump(ll_imdb, 'dumps/variable/ll_imdb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_imdb = pickle_load('dumps/variable/ll_imdb.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = ll_imdb.clas_databunchify(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y):\n",
    "    preds   = torch.argmax(preds, dim=1)\n",
    "    # y       = torch.argmax(y, dim =1)\n",
    "    correct = (preds == y).float()\n",
    "    acc     = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentimentanalyser.callbacks.callback import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TrainEvalCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainEvalCallback(Callback):\n",
    "    def begin_epoch(self):\n",
    "        self.model.train()\n",
    "        self.trainer.in_train = True\n",
    "        return\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.trainer.in_train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoggerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        self.lrs          = [[] for _ in self.opt.param_groups()]\n",
    "        return\n",
    "    \n",
    "    def after_batch(self):\n",
    "        if not self.in_train:\n",
    "            self.valid_losses.append(self.loss.detach().cpu())\n",
    "            return\n",
    "        \n",
    "        self.train_losses.append(self.loss.detach().cpu())\n",
    "        for pg, lr in zip(self.opt.param_groups, self.lrs):\n",
    "            lr.append(pg['lr'])\n",
    "        return\n",
    "    \n",
    "    def plot(self, skip_last=0, pgid=-1):\n",
    "        losses = [loss.item() for loss in self.train_losses]\n",
    "        lrs    = self.lrs[pgid]\n",
    "        n      = len(losses) - skip_last\n",
    "        \n",
    "        plt.xscale('log')\n",
    "        plt.plot(lrs[:n], losses[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self, data, model, loss_func, opt, cbs):\n",
    "        self.data, self.model    = data, model\n",
    "        self.loss_func, self.opt = loss_func, opt\n",
    "        self.cbs = cbs\n",
    "    \n",
    "    def add_cbs(self, cbs):\n",
    "        [self.add_cb(cb) for cb in cbs]\n",
    "    \n",
    "    def one_batch(self, xb, yb):\n",
    "        try:\n",
    "            self.xb, self.yb = xb.cuda(), yb.cuda()\n",
    "\n",
    "            self('begin_batch')\n",
    "            self.preds  = self.model(self.xb)\n",
    "            self('after_pred')\n",
    "            self.loss   = self.loss_func(self.preds, self.yb)\n",
    "            self('after_loss')\n",
    "            self.losses.append(self.loss.detach().item())\n",
    "            self.acc   += accuracy(self.preds, self.yb).item() \n",
    "\n",
    "            if not self.in_train: return\n",
    "\n",
    "            self.loss.backward()\n",
    "            self('after_backward')\n",
    "            self.opt.step()\n",
    "            self('after_step')\n",
    "            self.opt.zero_grad()\n",
    "        except CancelBatchException:\n",
    "            self('after_cancel_batch')\n",
    "        finally:\n",
    "            self('after_batch')\n",
    "        return\n",
    "    \n",
    "    def all_batches(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        try:\n",
    "            for xb, yb in tqdm(dl, leave=False):\n",
    "                self.one_batch(xb, yb)\n",
    "        except CancelEpochException:\n",
    "            self('after_cancel_epoch')\n",
    "        return \n",
    "    \n",
    "    def fit(self, epochs=3):\n",
    "        try:\n",
    "            for cb in self.cbs:\n",
    "                cb.set_trainer(self)\n",
    "            self('begin_fit')\n",
    "            self.model = self.model.cuda()\n",
    "            for epoch in tqdm(range(epochs)):\n",
    "                self.start_time = time.time()\n",
    "                self.epoch = epoch\n",
    "\n",
    "                # Training Loop\n",
    "                if not self('begin_epoch'):\n",
    "                    self.train_loss, self.train_acc = self.all_batches(self.data.train_dl)\n",
    "\n",
    "                # Validation Loop\n",
    "                with torch.no_grad():\n",
    "                    if not self('begin_validate'):\n",
    "                        self.valid_loss, self.valid_acc = self.all_batches(self.data.valid_dl)\n",
    "\n",
    "                elapsed_time = time.strftime('%M:%S', time.gmtime(time.time() - self.start_time))\n",
    "                print(f'Epoch: {self.epoch} | Time [min:sec]: {elapsed_time}')\n",
    "                print(f'Train Loss: {sum(self.train_loss)/len(self.train_loss):.4f} | Train acc: {self.train_acc/len(self.train_loss)*100:.2f}%')\n",
    "                print(f'Valid Loss: {sum(self.valid_loss)/len(self.valid_loss):.4f} | Valid acc: {self.valid_acc/len(self.valid_loss)*100:.2f}%')\n",
    "        except CancelTrainException:\n",
    "            self('after_cancel_train')\n",
    "        finally:\n",
    "            self('after_fit')\n",
    "    def __call__(self, cb_name):\n",
    "        res = True\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            res = cb(cb_name) and res\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lengths(x):\n",
    "    return x.size(1) - (x == 1).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model0(nn.Module):\n",
    "    def __init__(self, vocab_size=proc_num.vocab_size, num_layers=2,\n",
    "                 hidden_size=50, output_size=2, bidirectional=True,\n",
    "                 padding_idx=1, bs=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size, self.hidden_size, self.output_size   = vocab_size, hidden_size, output_size\n",
    "        self.num_layers, self.bidirectional, self.padding_idx = num_layers, bidirectional, padding_idx\n",
    "        self.bs = bs\n",
    "        \n",
    "        self.bidir          = 2 if bidirectional is True else 1\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.hidden_size, padding_idx=self.padding_idx)\n",
    "        \n",
    "        self.dropout   = nn.Dropout()\n",
    "        \n",
    "        self.rnn       = nn.LSTM(self.hidden_size, self.hidden_size,\n",
    "                                 num_layers=self.num_layers,\n",
    "                                 batch_first=True,\n",
    "                                 bidirectional=self.bidirectional)\n",
    "        \n",
    "        \n",
    "        self.bn        = nn.BatchNorm1d(self.hidden_size * self.bidir * self.num_layers)\n",
    "        self.fc        = nn.Linear(self.hidden_size * self.bidir * self.num_layers, self.output_size)\n",
    "        \n",
    "        self.softmax   = nn.Softmax(dim=1)\n",
    "        return\n",
    "    \n",
    "    def forward(self, texts):\n",
    "        text_lengths = get_lengths(texts)\n",
    "        embeded = self.dropout(self.embedding(texts))\n",
    "        packed_embed = nn.utils.rnn.pack_padded_sequence(embeded, text_lengths, batch_first=True)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embed)\n",
    "        \n",
    "        hidden = self.dropout(torch.cat([h for h in hidden], dim=1))\n",
    "        linear = self.fc(hidden)\n",
    "        return linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model0(num_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(imdb_data, model, loss_func, opt, cbs=[TrainEvalCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ff2b970a2d4ffbab96cbecf2d5f7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af262434c70488c9e5d2628b74cf329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=391), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-98eb647c9681>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-122-27840f136a7d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;31m# Training Loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# Validation Loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-27840f136a7d>\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self, dl)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-27840f136a7d>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, xb, yb)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macc\u001b[0m   \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'losses'"
     ]
    }
   ],
   "source": [
    "trainer.fit(epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
